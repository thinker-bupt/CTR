{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import os\n",
    "os.environ['TF_KERAS'] = '1'\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import pickle\n",
    "import time\n",
    "import keras\n",
    "import gc\n",
    "\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import *\n",
    "from sklearn.preprocessing import *\n",
    "from sklearn.metrics import *\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.utils import *\n",
    "from tensorflow.keras.losses import *\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.callbacks import *\n",
    "from tensorflow.keras.optimizers import *\n",
    "from tensorflow.keras.initializers import *\n",
    "from tensorflow.keras.regularizers import *\n",
    "from tensorflow.keras import initializers\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras import constraints\n",
    "from keras_layer_normalization import LayerNormalization\n",
    "\n",
    "from tensorflow.python.framework import ops\n",
    "from tensorflow.python.ops import math_ops\n",
    "from tensorflow.python.framework import smart_cond\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "# from keras_radam import RAdam\n",
    "from keras_multi_head import MultiHeadAttention\n",
    "# from keras_lookahead import Lookahead\n",
    "# from keras_transformer import *\n",
    "\n",
    "seed = 2020\n",
    "os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.is_gpu_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>I1</th>\n",
       "      <th>I2</th>\n",
       "      <th>I3</th>\n",
       "      <th>I4</th>\n",
       "      <th>I5</th>\n",
       "      <th>I6</th>\n",
       "      <th>I7</th>\n",
       "      <th>I8</th>\n",
       "      <th>I9</th>\n",
       "      <th>...</th>\n",
       "      <th>C17</th>\n",
       "      <th>C18</th>\n",
       "      <th>C19</th>\n",
       "      <th>C20</th>\n",
       "      <th>C21</th>\n",
       "      <th>C22</th>\n",
       "      <th>C23</th>\n",
       "      <th>C24</th>\n",
       "      <th>C25</th>\n",
       "      <th>C26</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.133301</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.416748</td>\n",
       "      <td>0.055542</td>\n",
       "      <td>0.199951</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>4883</td>\n",
       "      <td>268</td>\n",
       "      <td>3</td>\n",
       "      <td>22746</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>92924</td>\n",
       "      <td>85</td>\n",
       "      <td>48299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333252</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.111084</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.071411</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>3473</td>\n",
       "      <td>268</td>\n",
       "      <td>1</td>\n",
       "      <td>285940</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>31806</td>\n",
       "      <td>85</td>\n",
       "      <td>36596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333252</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.333252</td>\n",
       "      <td>0.066650</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>1002</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>676979</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>27604</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.529297</td>\n",
       "      <td>0.133301</td>\n",
       "      <td>0.111084</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.222168</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2289</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>68019</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.083313</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.133301</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.066650</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>759</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>99687</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>84096</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label        I1        I2        I3        I4        I5        I6  \\\n",
       "0      0  0.000000  0.000000  0.133301  0.000000  0.416748  0.055542   \n",
       "1      0  0.000000  0.000000  0.333252  0.000000  0.250000  0.111084   \n",
       "2      0  0.000000  0.000000  0.000000  0.333252  0.375000  0.333252   \n",
       "3      0  0.000000  0.529297  0.133301  0.111084  0.500000  0.222168   \n",
       "4      0  0.083313  0.000000  0.133301  0.000000  0.000000  0.000000   \n",
       "\n",
       "         I7   I8        I9  ...  C17   C18  C19  C20     C21  C22  C23    C24  \\\n",
       "0  0.199951  0.0  0.500000  ...    9  4883  268    3   22746    0    3  92924   \n",
       "1  0.000000  0.0  0.071411  ...    0  3473  268    1  285940    0    3  31806   \n",
       "2  0.066650  0.0  0.500000  ...    6  1002    1    0  676979   12    3  27604   \n",
       "3  0.000000  0.0  0.000000  ...    1  2289    1    0       0    0    3  68019   \n",
       "4  0.066650  0.0  0.000000  ...    1   759    1    0   99687    0    2  84096   \n",
       "\n",
       "   C25    C26  \n",
       "0   85  48299  \n",
       "1   85  36596  \n",
       "2    1      1  \n",
       "3    1      1  \n",
       "4    1      1  \n",
       "\n",
       "[5 rows x 40 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_pickle('/data/trans_df_4.pkl')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label         2\n",
       "I1           13\n",
       "I2           17\n",
       "I3           16\n",
       "I4           10\n",
       "I5           23\n",
       "I6           19\n",
       "I7           16\n",
       "I8           13\n",
       "I9           15\n",
       "I10           4\n",
       "I11           8\n",
       "I12          12\n",
       "I13          13\n",
       "C1         1460\n",
       "C2          561\n",
       "C3       794520\n",
       "C4       408541\n",
       "C5          305\n",
       "C6           23\n",
       "C7        12311\n",
       "C8          633\n",
       "C9            3\n",
       "C10       65275\n",
       "C11        5463\n",
       "C12      785111\n",
       "C13        3187\n",
       "C14          27\n",
       "C15       13255\n",
       "C16      670200\n",
       "C17          10\n",
       "C18        5128\n",
       "C19        2133\n",
       "C20           4\n",
       "C21      754987\n",
       "C22          18\n",
       "C23          15\n",
       "C24      120120\n",
       "C25         100\n",
       "C26       81747\n",
       "dtype: int64"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1645512064.6845841"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "> lrange 56_online_1645512064 0 10\n",
      "\n",
      "1) \"688\"\n",
      "2) \"170\"\n",
      "3) \"2715\"\n",
      "4) \"2711\"\n",
      "5) \"1957\"\n",
      "6) \"49\"\n",
      "7) \"55\"\n",
      "8) \"630\"\n",
      "9) \"3496\"\n",
      "10) \"17\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "a = \"\"\"\n",
    "> lrange 56_online_1645512064 0 10\n",
    "\n",
    "1) \"688\"\n",
    "2) \"170\"\n",
    "3) \"2715\"\n",
    "4) \"2711\"\n",
    "5) \"1957\"\n",
    "6) \"49\"\n",
    "7) \"55\"\n",
    "8) \"630\"\n",
    "9) \"3496\"\n",
    "10) \"17\"\n",
    "\"\"\"\n",
    "\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>I1</th>\n",
       "      <th>I2</th>\n",
       "      <th>I3</th>\n",
       "      <th>I4</th>\n",
       "      <th>I5</th>\n",
       "      <th>I6</th>\n",
       "      <th>I7</th>\n",
       "      <th>I8</th>\n",
       "      <th>I9</th>\n",
       "      <th>I10</th>\n",
       "      <th>I11</th>\n",
       "      <th>I12</th>\n",
       "      <th>I13</th>\n",
       "      <th>C1</th>\n",
       "      <th>C2</th>\n",
       "      <th>C3</th>\n",
       "      <th>C4</th>\n",
       "      <th>C5</th>\n",
       "      <th>C6</th>\n",
       "      <th>C7</th>\n",
       "      <th>C8</th>\n",
       "      <th>C9</th>\n",
       "      <th>C10</th>\n",
       "      <th>C11</th>\n",
       "      <th>C12</th>\n",
       "      <th>C13</th>\n",
       "      <th>C14</th>\n",
       "      <th>C15</th>\n",
       "      <th>C16</th>\n",
       "      <th>C17</th>\n",
       "      <th>C18</th>\n",
       "      <th>C19</th>\n",
       "      <th>C20</th>\n",
       "      <th>C21</th>\n",
       "      <th>C22</th>\n",
       "      <th>C23</th>\n",
       "      <th>C24</th>\n",
       "      <th>C25</th>\n",
       "      <th>C26</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>629</td>\n",
       "      <td>282</td>\n",
       "      <td>0</td>\n",
       "      <td>196621</td>\n",
       "      <td>43</td>\n",
       "      <td>11</td>\n",
       "      <td>10635</td>\n",
       "      <td>80</td>\n",
       "      <td>2</td>\n",
       "      <td>42964</td>\n",
       "      <td>3832</td>\n",
       "      <td>0</td>\n",
       "      <td>489</td>\n",
       "      <td>4</td>\n",
       "      <td>7188</td>\n",
       "      <td>358863</td>\n",
       "      <td>9</td>\n",
       "      <td>4883</td>\n",
       "      <td>268</td>\n",
       "      <td>3</td>\n",
       "      <td>22746</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>92924</td>\n",
       "      <td>85</td>\n",
       "      <td>48299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.08</td>\n",
       "      <td>629</td>\n",
       "      <td>532</td>\n",
       "      <td>345334</td>\n",
       "      <td>103823</td>\n",
       "      <td>43</td>\n",
       "      <td>22</td>\n",
       "      <td>7057</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>11020</td>\n",
       "      <td>1660</td>\n",
       "      <td>301203</td>\n",
       "      <td>2697</td>\n",
       "      <td>18</td>\n",
       "      <td>11945</td>\n",
       "      <td>526435</td>\n",
       "      <td>0</td>\n",
       "      <td>3473</td>\n",
       "      <td>268</td>\n",
       "      <td>1</td>\n",
       "      <td>285940</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>31806</td>\n",
       "      <td>85</td>\n",
       "      <td>36596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.42</td>\n",
       "      <td>228</td>\n",
       "      <td>29</td>\n",
       "      <td>8738</td>\n",
       "      <td>309108</td>\n",
       "      <td>43</td>\n",
       "      <td>11</td>\n",
       "      <td>9552</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>15031</td>\n",
       "      <td>2000</td>\n",
       "      <td>440882</td>\n",
       "      <td>2161</td>\n",
       "      <td>2</td>\n",
       "      <td>5675</td>\n",
       "      <td>141390</td>\n",
       "      <td>6</td>\n",
       "      <td>1002</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>676979</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>27604</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.08</td>\n",
       "      <td>629</td>\n",
       "      <td>102</td>\n",
       "      <td>0</td>\n",
       "      <td>73123</td>\n",
       "      <td>43</td>\n",
       "      <td>22</td>\n",
       "      <td>2262</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>61268</td>\n",
       "      <td>4911</td>\n",
       "      <td>0</td>\n",
       "      <td>674</td>\n",
       "      <td>2</td>\n",
       "      <td>1234</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2289</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>68019</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>820</td>\n",
       "      <td>397</td>\n",
       "      <td>0</td>\n",
       "      <td>397510</td>\n",
       "      <td>43</td>\n",
       "      <td>3</td>\n",
       "      <td>8362</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>20980</td>\n",
       "      <td>4928</td>\n",
       "      <td>314635</td>\n",
       "      <td>3012</td>\n",
       "      <td>4</td>\n",
       "      <td>7407</td>\n",
       "      <td>4535</td>\n",
       "      <td>1</td>\n",
       "      <td>759</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>99687</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>84096</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label   I1   I2   I3   I4   I5   I6   I7   I8   I9  I10  I11  I12  I13  \\\n",
       "0      0 0.00 0.00 0.13 0.00 0.42 0.06 0.20 0.00 0.50 0.00 0.00 0.00 0.00   \n",
       "1      0 0.00 0.00 0.33 0.00 0.25 0.11 0.00 0.00 0.07 0.00 0.00 0.00 0.08   \n",
       "2      0 0.00 0.00 0.00 0.33 0.38 0.33 0.07 0.00 0.50 0.00 0.14 0.09 0.42   \n",
       "3      0 0.00 0.53 0.13 0.11 0.50 0.22 0.00 0.00 0.00 0.00 0.00 0.00 0.08   \n",
       "4      0 0.08 0.00 0.13 0.00 0.00 0.00 0.07 0.00 0.00 0.00 0.00 0.00 0.00   \n",
       "\n",
       "    C1   C2      C3      C4  C5  C6     C7  C8  C9    C10   C11     C12   C13  \\\n",
       "0  629  282       0  196621  43  11  10635  80   2  42964  3832       0   489   \n",
       "1  629  532  345334  103823  43  22   7057  24   2  11020  1660  301203  2697   \n",
       "2  228   29    8738  309108  43  11   9552  24   2  15031  2000  440882  2161   \n",
       "3  629  102       0   73123  43  22   2262  24   2  61268  4911       0   674   \n",
       "4  820  397       0  397510  43   3   8362  24   2  20980  4928  314635  3012   \n",
       "\n",
       "   C14    C15     C16  C17   C18  C19  C20     C21  C22  C23    C24  C25  \\\n",
       "0    4   7188  358863    9  4883  268    3   22746    0    3  92924   85   \n",
       "1   18  11945  526435    0  3473  268    1  285940    0    3  31806   85   \n",
       "2    2   5675  141390    6  1002    1    0  676979   12    3  27604    1   \n",
       "3    2   1234       0    1  2289    1    0       0    0    3  68019    1   \n",
       "4    4   7407    4535    1   759    1    0   99687    0    2  84096    1   \n",
       "\n",
       "     C26  \n",
       "0  48299  \n",
       "1  36596  \n",
       "2      1  \n",
       "3      1  \n",
       "4      1  "
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_columns', None) \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>I1</th>\n",
       "      <th>I2</th>\n",
       "      <th>I3</th>\n",
       "      <th>I4</th>\n",
       "      <th>I5</th>\n",
       "      <th>I6</th>\n",
       "      <th>I7</th>\n",
       "      <th>I8</th>\n",
       "      <th>I9</th>\n",
       "      <th>I10</th>\n",
       "      <th>I11</th>\n",
       "      <th>I12</th>\n",
       "      <th>I13</th>\n",
       "      <th>C1</th>\n",
       "      <th>C2</th>\n",
       "      <th>C3</th>\n",
       "      <th>C4</th>\n",
       "      <th>C5</th>\n",
       "      <th>C6</th>\n",
       "      <th>C7</th>\n",
       "      <th>C8</th>\n",
       "      <th>C9</th>\n",
       "      <th>C10</th>\n",
       "      <th>C11</th>\n",
       "      <th>C12</th>\n",
       "      <th>C13</th>\n",
       "      <th>C14</th>\n",
       "      <th>C15</th>\n",
       "      <th>C16</th>\n",
       "      <th>C17</th>\n",
       "      <th>C18</th>\n",
       "      <th>C19</th>\n",
       "      <th>C20</th>\n",
       "      <th>C21</th>\n",
       "      <th>C22</th>\n",
       "      <th>C23</th>\n",
       "      <th>C24</th>\n",
       "      <th>C25</th>\n",
       "      <th>C26</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>629</td>\n",
       "      <td>282</td>\n",
       "      <td>0</td>\n",
       "      <td>196621</td>\n",
       "      <td>43</td>\n",
       "      <td>11</td>\n",
       "      <td>10635</td>\n",
       "      <td>80</td>\n",
       "      <td>2</td>\n",
       "      <td>42964</td>\n",
       "      <td>3832</td>\n",
       "      <td>0</td>\n",
       "      <td>489</td>\n",
       "      <td>4</td>\n",
       "      <td>7188</td>\n",
       "      <td>358863</td>\n",
       "      <td>9</td>\n",
       "      <td>4883</td>\n",
       "      <td>268</td>\n",
       "      <td>3</td>\n",
       "      <td>22746</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>92924</td>\n",
       "      <td>85</td>\n",
       "      <td>48299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.08</td>\n",
       "      <td>629</td>\n",
       "      <td>532</td>\n",
       "      <td>345334</td>\n",
       "      <td>103823</td>\n",
       "      <td>43</td>\n",
       "      <td>22</td>\n",
       "      <td>7057</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>11020</td>\n",
       "      <td>1660</td>\n",
       "      <td>301203</td>\n",
       "      <td>2697</td>\n",
       "      <td>18</td>\n",
       "      <td>11945</td>\n",
       "      <td>526435</td>\n",
       "      <td>0</td>\n",
       "      <td>3473</td>\n",
       "      <td>268</td>\n",
       "      <td>1</td>\n",
       "      <td>285940</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>31806</td>\n",
       "      <td>85</td>\n",
       "      <td>36596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.42</td>\n",
       "      <td>228</td>\n",
       "      <td>29</td>\n",
       "      <td>8738</td>\n",
       "      <td>309108</td>\n",
       "      <td>43</td>\n",
       "      <td>11</td>\n",
       "      <td>9552</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>15031</td>\n",
       "      <td>2000</td>\n",
       "      <td>440882</td>\n",
       "      <td>2161</td>\n",
       "      <td>2</td>\n",
       "      <td>5675</td>\n",
       "      <td>141390</td>\n",
       "      <td>6</td>\n",
       "      <td>1002</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>676979</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>27604</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.08</td>\n",
       "      <td>629</td>\n",
       "      <td>102</td>\n",
       "      <td>0</td>\n",
       "      <td>73123</td>\n",
       "      <td>43</td>\n",
       "      <td>22</td>\n",
       "      <td>2262</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>61268</td>\n",
       "      <td>4911</td>\n",
       "      <td>0</td>\n",
       "      <td>674</td>\n",
       "      <td>2</td>\n",
       "      <td>1234</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2289</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>68019</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>820</td>\n",
       "      <td>397</td>\n",
       "      <td>0</td>\n",
       "      <td>397510</td>\n",
       "      <td>43</td>\n",
       "      <td>3</td>\n",
       "      <td>8362</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>20980</td>\n",
       "      <td>4928</td>\n",
       "      <td>314635</td>\n",
       "      <td>3012</td>\n",
       "      <td>4</td>\n",
       "      <td>7407</td>\n",
       "      <td>4535</td>\n",
       "      <td>1</td>\n",
       "      <td>759</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>99687</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>84096</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label   I1   I2   I3   I4   I5   I6   I7   I8   I9  I10  I11  I12  I13  \\\n",
       "0      0 0.00 0.00 0.13 0.00 0.42 0.06 0.20 0.00 0.50 0.00 0.00 0.00 0.00   \n",
       "1      0 0.00 0.00 0.33 0.00 0.25 0.11 0.00 0.00 0.07 0.00 0.00 0.00 0.08   \n",
       "2      0 0.00 0.00 0.00 0.33 0.38 0.33 0.07 0.00 0.50 0.00 0.14 0.09 0.42   \n",
       "3      0 0.00 0.53 0.13 0.11 0.50 0.22 0.00 0.00 0.00 0.00 0.00 0.00 0.08   \n",
       "4      0 0.08 0.00 0.13 0.00 0.00 0.00 0.07 0.00 0.00 0.00 0.00 0.00 0.00   \n",
       "\n",
       "    C1   C2      C3      C4  C5  C6     C7  C8  C9    C10   C11     C12   C13  \\\n",
       "0  629  282       0  196621  43  11  10635  80   2  42964  3832       0   489   \n",
       "1  629  532  345334  103823  43  22   7057  24   2  11020  1660  301203  2697   \n",
       "2  228   29    8738  309108  43  11   9552  24   2  15031  2000  440882  2161   \n",
       "3  629  102       0   73123  43  22   2262  24   2  61268  4911       0   674   \n",
       "4  820  397       0  397510  43   3   8362  24   2  20980  4928  314635  3012   \n",
       "\n",
       "   C14    C15     C16  C17   C18  C19  C20     C21  C22  C23    C24  C25  \\\n",
       "0    4   7188  358863    9  4883  268    3   22746    0    3  92924   85   \n",
       "1   18  11945  526435    0  3473  268    1  285940    0    3  31806   85   \n",
       "2    2   5675  141390    6  1002    1    0  676979   12    3  27604    1   \n",
       "3    2   1234       0    1  2289    1    0       0    0    3  68019    1   \n",
       "4    4   7407    4535    1   759    1    0   99687    0    2  84096    1   \n",
       "\n",
       "     C26  \n",
       "0  48299  \n",
       "1  36596  \n",
       "2      1  \n",
       "3      1  \n",
       "4      1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.float_format', lambda x: '%.2f' % x)\n",
    "pd.set_option('max_columns', 50)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_features = ['C' + str(i) for i in range(1, 27)]\n",
    "dense_features = ['I' + str(i) for i in range(1, 14)]\n",
    "use_features = sparse_features + dense_features\n",
    "target = 'label'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((36672493, 39), (9168124, 39), (36672493,), (9168124,))"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fold_train_x, fold_valid_x, fold_train_y, fold_valid_y = train_test_split(\n",
    "    df[use_features], df[target], stratify=df[target], test_size=0.2, random_state=seed)\n",
    "fold_train_x.shape, fold_valid_x.shape, fold_train_y.shape, fold_valid_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1460, 561, 794520, 408541, 305, 23, 12311, 633, 3, 65275, 5463, 785111, 3187, 27, 13255, 670200, 10, 5128, 2133, 4, 754987, 18, 15, 120120, 100, 81747]\n"
     ]
    }
   ],
   "source": [
    "embed_list = df[sparse_features].nunique()\n",
    "print(list(embed_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# input_embedding_dim_list = [1460, 583, 10131227, 2202608, 305, 24, 12517, 633, 3, 93145, 5683, 8351593, 3194, 27, 14992, 5461306, 10, 5652, 2173, 4, 7046547, 18, 15, 286181, 105, 142572]\n",
    "input_embedding_dim_list = [1460, 561, 794520, 408541, 305, 23, 12311, 633, 3, 65275, 5463, 785111, 3187, 27, 13255, 670200, 10, 5128, 2133, 4, 754987, 18, 15, 120120, 100, 81747]\n",
    "# input_embedding_dim_list = [1460, 570, 1545893, 668222, 305, 24, 12399, 633, 3, 74829, 5557, 1518204, 3194, 27, 13883, 1231447, 10, 5310, 2151, 4, 1437678, 18, 15, 157463, 104, 99817]\n",
    "len(input_embedding_dim_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_keras():\n",
    "    K.clear_session()\n",
    "    config = tf.ConfigProto()\n",
    "    config.gpu_options.allow_growth=True   #不全部占满显存, 按需分配\n",
    "    sess = tf.Session(config=config)\n",
    "\n",
    "    K.set_session(sess)\n",
    "    gc.collect()\n",
    "    \n",
    "def auroc(y_true, y_pred):\n",
    "    return tf.py_func(roc_auc_score, (y_true, y_pred), tf.double)\n",
    "\n",
    "class record_logs(Callback):\n",
    "    def __init__(self, description, log_name):\n",
    "        self.description = description\n",
    "        self.log_name = log_name\n",
    "        self.now_time = time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime())\n",
    "        \n",
    "    def on_train_begin(self, epoch, logs=None):\n",
    "        with open(self.log_name, 'a+') as f:\n",
    "            f.writelines(self.now_time + '\\n')\n",
    "            f.writelines(self.description + '\\n')\n",
    "    \n",
    "    def on_epoch_begin(self, epoch, logs=None):\n",
    "        self.start_time = time.time()\n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        self.end_time = time.time()\n",
    "        self.last_time = self.end_time - self.start_time\n",
    "        logs['time'] = self.last_time\n",
    "        for i in logs:\n",
    "            logs[i] = np.round(logs[i], 6)\n",
    "        with open(self.log_name, 'a+') as f:\n",
    "            f.writelines('epoch ' + str(epoch + 1) + ':' + str(logs) + '\\n')\n",
    "\n",
    "class gen_data(Sequence):\n",
    "    def __init__(self, x_set, y_set, batch_size):\n",
    "        self.x, self.y = x_set, y_set\n",
    "        self.batch_size = batch_size\n",
    " \n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.x) / float(self.batch_size)))\n",
    " \n",
    "    def __getitem__(self, idx):\n",
    "        batch_x = self.x[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        batch_y = self.y[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    " \n",
    "        return np.array(batch_x), np.array(batch_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Gate(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(Gate, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        super(Gate, self).build(input_shape)  # Be sure to call this somewhere!\n",
    "\n",
    "    def call(self, inputs, **kwargs):\n",
    "        weight = Dense(1, activation='sigmoid', use_bias=False)(inputs)\n",
    "        return inputs * weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FM(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(FM, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        super(FM, self).build(input_shape)  # Be sure to call this somewhere!\n",
    "\n",
    "    def call(self, inputs, **kwargs):\n",
    "        concated_embeds_value = inputs\n",
    "        square_of_sum = tf.square(tf.reduce_sum(\n",
    "            concated_embeds_value, axis=1, keep_dims=True))\n",
    "        sum_of_square = tf.reduce_sum(\n",
    "            concated_embeds_value * concated_embeds_value, axis=1, keep_dims=True)\n",
    "        cross_term = square_of_sum - sum_of_square\n",
    "        cross_term = 0.5 * tf.reduce_sum(cross_term, axis=2, keep_dims=False)\n",
    "        return cross_term\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (None, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SENET(Layer):\n",
    "    def __init__(self, reduction_ratio=3, seed=1024, **kwargs):\n",
    "        self.reduction_ratio = reduction_ratio\n",
    "        self.seed = seed\n",
    "        super(SENET, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.field_size = input_shape[-2]\n",
    "        self.embedding_size = input_shape[-1]\n",
    "        self.reduction_size = max(1, self.field_size // self.reduction_ratio)\n",
    "\n",
    "        self.W_0 = self.add_weight(shape=(\n",
    "            self.field_size * self.embedding_size, self.field_size), initializer=glorot_normal(seed=self.seed), name=\"W_0\")\n",
    "        self.W_1 = self.add_weight(shape=(\n",
    "            self.field_size, self.reduction_size), initializer=glorot_normal(seed=self.seed), name=\"W_1\")\n",
    "        self.W_2 = self.add_weight(shape=(\n",
    "            self.reduction_size, self.field_size), initializer=glorot_normal(seed=self.seed), name=\"W_2\")\n",
    "        self.tensordot = tf.keras.layers.Lambda(\n",
    "            lambda x: tf.tensordot(x[0], x[1], axes=(-1, 0)))\n",
    "        super(SENET, self).build(input_shape)\n",
    "\n",
    "    def call(self, inputs, training=None, **kwargs):\n",
    "        # Z = tf.reduce_mean(inputs, axis=-1)\n",
    "        Z = Flatten()(inputs)\n",
    "        # Z = Conv1D(filters=self.embedding_size, kernel_size=1, strides=1, padding='valid')(inputs)\n",
    "        # Z = tf.reduce_mean(Z, axis=-1, keepdims=False)\n",
    "        Z = tf.nn.relu(self.tensordot([Z, self.W_0]))\n",
    "        Z = tf.nn.sigmoid(self.tensordot([Z, self.W_1]))\n",
    "        Z = tf.nn.sigmoid(self.tensordot([Z, self.W_2]))\n",
    "        V = tf.multiply(inputs, tf.expand_dims(Z, axis=2))\n",
    "        return V\n",
    "        # return tf.split(V, self.field_size, axis=1)\n",
    "        \n",
    "        \n",
    "# class DNNSENET(Layer):\n",
    "#     def __init__(self, reduction_ratio=2, seed=1024, feature_size=256, **kwargs):\n",
    "#         self.feature_size = feature_size\n",
    "#         self.reduction_ratio = reduction_ratio\n",
    "#         self.seed = seed\n",
    "#         super(DNNSENET, self).__init__(**kwargs)\n",
    "\n",
    "#     def build(self, input_shape):\n",
    "#         self.embedding_size = input_shape[-1]\n",
    "#         self.reduction_size = max(1, self.embedding_size // self.reduction_ratio)\n",
    "\n",
    "#         self.W_0 = self.add_weight(shape=(\n",
    "#             self.embedding_size, self.reduction_size), initializer=glorot_normal(seed=self.seed), name=\"W_0\")\n",
    "#         self.W_1 = self.add_weight(shape=(\n",
    "#             self.reduction_size, self.embedding_size), initializer=glorot_normal(seed=self.seed), name=\"W_1\")\n",
    "#         self.tensordot = tf.keras.layers.Lambda(\n",
    "#             lambda x: tf.tensordot(x[0], x[1], axes=(-1, 0)))\n",
    "#         super(DNNSENET, self).build(input_shape)\n",
    "\n",
    "#     def call(self, inputs, training=None, **kwargs):\n",
    "#         Z = inputs\n",
    "#         Z = tf.nn.relu(self.tensordot([Z, self.W_0]))\n",
    "#         Z = tf.nn.sigmoid(self.tensordot([Z, self.W_1]))\n",
    "#         return Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CrossNet_V1(Layer):\n",
    "    def __init__(self, layer_num=2, l2_reg=0, seed=1024, **kwargs):\n",
    "        self.layer_num = layer_num\n",
    "        self.l2_reg = l2_reg\n",
    "        self.seed = seed\n",
    "        super(CrossNet_V1, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        dim = int(input_shape[-1])\n",
    "        self.kernels = [self.add_weight(name='kernel' + str(i),\n",
    "                                        shape=(dim, 1),\n",
    "                                        initializer=glorot_normal(\n",
    "                                            seed=self.seed),\n",
    "                                        regularizer=l2(self.l2_reg),\n",
    "                                        trainable=True) for i in range(self.layer_num)]\n",
    "        self.bias = [self.add_weight(name='bias' + str(i),\n",
    "                                     shape=(dim, 1),\n",
    "                                     initializer=Zeros(),\n",
    "                                     trainable=True) for i in range(self.layer_num)]\n",
    "        super(CrossNet_V1, self).build(input_shape)\n",
    "\n",
    "    def call(self, inputs, **kwargs):\n",
    "        x_0 = tf.expand_dims(inputs, axis=2)\n",
    "        x_l = x_0\n",
    "        for i in range(self.layer_num):\n",
    "            xl_w = tf.tensordot(x_l, self.kernels[i], axes=(1, 0))\n",
    "            dot_ = tf.matmul(x_0, xl_w)\n",
    "            x_l = dot_ + self.bias[i] + x_l\n",
    "        x_l = tf.squeeze(x_l, axis=2)\n",
    "        return x_l\n",
    "    \n",
    "\n",
    "class CrossNet_V2(Layer):\n",
    "    def __init__(self, layer_num=3, l2_reg=0, seed=1024, **kwargs):\n",
    "        self.layer_num = layer_num\n",
    "        self.l2_reg = l2_reg\n",
    "        self.seed = seed\n",
    "        super(CrossNet_V2, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        dim = int(input_shape[-1])\n",
    "        self.kernels = [self.add_weight(name='kernel' + str(i),\n",
    "                                        shape=(dim, dim),\n",
    "                                        initializer=glorot_normal(seed=self.seed),\n",
    "                                        regularizer=l2(self.l2_reg),\n",
    "                                        trainable=True) for i in range(self.layer_num)]\n",
    "        self.bias = [self.add_weight(name='bias' + str(i),\n",
    "                                     shape=(dim, 1),\n",
    "                                     initializer=Zeros(),\n",
    "                                     trainable=True) for i in range(self.layer_num)]\n",
    "        super(CrossNet_V2, self).build(input_shape)\n",
    "\n",
    "    def call(self, inputs, **kwargs):\n",
    "        x_0 = tf.expand_dims(inputs, axis=2)\n",
    "        x_l = x_0\n",
    "        for i in range(self.layer_num):\n",
    "            wl_xl = tf.matmul(self.kernels[i], x_l)\n",
    "            x_m = wl_xl + self.bias[i]\n",
    "            x_l = x_0 * x_m + x_l\n",
    "        x_l = tf.squeeze(x_l, axis=2)\n",
    "        return x_l\n",
    "\n",
    "    def get_config(self, ):\n",
    "        config = {'layer_num': self.layer_num,\n",
    "                  'l2_reg': self.l2_reg, 'seed': self.seed}\n",
    "        base_config = super(CrossNet_V2, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CrossNetMix(Layer):\n",
    "    def __init__(self, low_rank=32, num_experts=6, layer_num=2, seed=2020):\n",
    "        self.low_rank = low_rank\n",
    "        self.num_experts = num_experts\n",
    "        self.layer_num = layer_num\n",
    "        self.seed = seed\n",
    "        super(CrossNetMix, self).__init__()\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        # U: (in_features, low_rank)\n",
    "        self.in_features = int(input_shape[1])\n",
    "        self.U_list = [self.add_weight(name='kernel_U' + str(i),\n",
    "                                       shape=(self.num_experts, self.in_features, self.low_rank),\n",
    "                                       initializer=glorot_normal(seed=self.seed))\n",
    "                                       for i in range(self.layer_num)]\n",
    "        # V: (in_features, low_rank)\n",
    "        self.V_list = [self.add_weight(name='kernel_V' + str(i),\n",
    "                                       shape=(self.num_experts, self.in_features, self.low_rank),\n",
    "                                       initializer=glorot_normal(seed=self.seed))\n",
    "                                       for i in range(self.layer_num)]\n",
    "\n",
    "        # C: (low_rank, low_rank)\n",
    "        self.C_list = [self.add_weight(name='kernel_C' + str(i),\n",
    "                                       shape=(self.num_experts, self.low_rank, self.low_rank),\n",
    "                                       initializer=glorot_normal(seed=self.seed))\n",
    "                                       for i in range(self.layer_num)]\n",
    "\n",
    "        self.gating = [Dense(1, use_bias=False) for i in range(self.num_experts)]\n",
    "\n",
    "        self.bias = [self.add_weight(name='bias' + str(i),\n",
    "                                    shape=(self.in_features, 1),\n",
    "                                    initializer=Zeros()) \n",
    "                                    for i in range(self.layer_num)]\n",
    "        super(CrossNetMix, self).build(input_shape)\n",
    "\n",
    "    def call(self, inputs, **kwargs):\n",
    "        # (bs, in_features, 1)\n",
    "        x_0 = tf.expand_dims(inputs, 2)  \n",
    "        x_l = x_0\n",
    "        for i in range(self.layer_num):\n",
    "            output_of_experts = []\n",
    "            gating_score_of_experts = []\n",
    "            for expert_id in range(self.num_experts):\n",
    "                # (bs, in_features) -> (bs, 1)\n",
    "                gating_score_of_experts.append(self.gating[expert_id](tf.squeeze(x_l, 2)))\n",
    "\n",
    "                # (bs, in_features, 1) -> (bs, low_rank, 1)\n",
    "                v_x = tf.matmul(tf.transpose(self.V_list[i][expert_id]), x_l)\n",
    "\n",
    "                v_x = tf.tanh(v_x)\n",
    "                \n",
    "                # (bs, low_rank, 1) -> (bs, low_rank, 1)\n",
    "                v_x = tf.matmul(self.C_list[i][expert_id], v_x)\n",
    "                v_x = tf.tanh(v_x)\n",
    "\n",
    "                # (bs, low_rank, 1) -> (bs, in_features, 1)\n",
    "                uv_x = tf.matmul(self.U_list[i][expert_id], v_x)  \n",
    "\n",
    "                dot_ = uv_x + self.bias[i]\n",
    "                \n",
    "                # (bs, in_features, 1)\n",
    "                dot_ = x_0 * dot_ \n",
    "\n",
    "                output_of_experts.append(tf.squeeze(dot_, 2))\n",
    "\n",
    "            # (bs, in_features, num_experts)\n",
    "            output_of_experts = tf.stack(output_of_experts, 2)  \n",
    "            # (bs, num_experts, 1)\n",
    "            gating_score_of_experts = tf.stack(gating_score_of_experts, 1)  \n",
    "            gating_value = tf.nn.softmax(gating_score_of_experts, 1)\n",
    "            \n",
    "            moe_out = tf.matmul(output_of_experts, gating_value)\n",
    "            x_l = moe_out + x_l  # (bs, in_features, 1)\n",
    "\n",
    "        x_l = tf.squeeze(x_l, -1)  # (bs, in_features)\n",
    "        return x_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CrossFM(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(CrossFM, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.field_size = input_shape[-2]\n",
    "        self.embedding_size = input_shape[-1]\n",
    "        super(CrossFM, self).build(input_shape)  # Be sure to call this somewhere!\n",
    "        \n",
    "    def call(self, inputs, **kwargs):\n",
    "        x = inputs\n",
    "        result = []\n",
    "        for i in range(self.field_size):\n",
    "            cur = x[:, i]\n",
    "            other = tf.concat([x[:, :i], x[:, i:]], axis=1)\n",
    "            other_embed = Dense(self.embedding_size, activation='relu')(Flatten()(other))\n",
    "            res = tf.reduce_sum(cur * other_embed, axis=1, keepdims=True)\n",
    "            result.append(res)\n",
    "        result = tf.concat(result, axis=1)\n",
    "        return result\n",
    "    \n",
    "    \n",
    "class WeightedFM(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(WeightedFM, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.field_size = input_shape[-2]\n",
    "        self.embedding_size = input_shape[-1]\n",
    "        super(WeightedFM, self).build(input_shape)  # Be sure to call this somewhere!\n",
    "        \n",
    "    def call(self, inputs, **kwargs):\n",
    "        x = inputs\n",
    "        result = []\n",
    "        for i in range(self.field_size):\n",
    "            cur = x[:, i]\n",
    "            other = tf.concat([x[:, :i], x[:, i:]], axis=1)\n",
    "            other_embed = Dense(self.embedding_size, activation='relu')(Flatten()(other))\n",
    "            res = tf.reduce_sum(cur * other_embed, axis=1, keepdims=True)\n",
    "            res = res * cur\n",
    "            res = tf.expand_dims(res, axis=1)\n",
    "            result.append(res)\n",
    "        result = tf.concat(result, axis=1)\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImpFM(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(ImpFM, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.field_size = input_shape[-2]\n",
    "        self.embedding_size = input_shape[-1]\n",
    "        super(ImpFM, self).build(input_shape)  # Be sure to call this somewhere!\n",
    "        \n",
    "    def call(self, inputs, **kwargs):\n",
    "        x = inputs\n",
    "        result = []\n",
    "        for i in range(self.field_size):\n",
    "            cur = x[:, i:i + 1]\n",
    "            other = tf.concat([x[:, :i], x[:, i + 1:]], axis=1)\n",
    "            other_embed = Dense(self.embedding_size, activation='relu')(Flatten()(other))\n",
    "            other_embed = tf.expand_dims(other_embed, 1) \n",
    "            res = cur * other_embed\n",
    "            result.append(res)\n",
    "        result = tf.concat(result, axis=1)\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tencent senet\n",
    "\n",
    "class SENET_V2(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(SENET_V2, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.field_size = len(input_shape)\n",
    "        super(SENET_V2, self).build(input_shape)  # Be sure to call this somewhere!\n",
    "        \n",
    "    def call(self, inputs, **kwargs):\n",
    "        flat = tf.concat(inputs, axis=1)\n",
    "        flat = Flatten()(flat)\n",
    "        # print('field size:', self.field_size)\n",
    "        # print('flat shape', flat.shape)\n",
    "        # print('inputs shape', inputs[0].shape)\n",
    "        weight = Dense(self.field_size, activation='sigmoid', use_bias=True)(flat)\n",
    "        result = []\n",
    "        for i in range(self.field_size):\n",
    "            x = inputs[i] * weight[:, None, i:i + 1]\n",
    "            result.append(x)\n",
    "        result = tf.concat(result, axis=1)\n",
    "        return result\n",
    "    \n",
    "\n",
    "# class SENET_V3(Layer):\n",
    "#     def __init__(self, **kwargs):\n",
    "#         super(SENET_V3, self).__init__(**kwargs)\n",
    "\n",
    "#     def build(self, input_shape):\n",
    "#         self.field_size = len(input_shape)\n",
    "#         super(SENET_V3, self).build(input_shape)  # Be sure to call this somewhere!\n",
    "        \n",
    "#     def call(self, inputs, **kwargs):\n",
    "#         # print('field size:', self.field_size)\n",
    "#         result = []\n",
    "#         for i in range(self.field_size):\n",
    "#             x = inputs[i]\n",
    "#             weight = Dense(1, activation='sigmoid', use_bias=False)(x)\n",
    "#             weighted_x = x * weight\n",
    "#             result.append(weighted_x)\n",
    "#         result = tf.concat(result, axis=1)\n",
    "#         return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "class MIFM(Layer):\n",
    "    def __init__(self, inter_fields=2,  **kwargs):\n",
    "        self.inter_fields = inter_fields\n",
    "        super(MIFM, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.num_fields = int(input_shape[1])\n",
    "        self.embed_size = int(input_shape[2])\n",
    "        super(MIFM, self).build(input_shape)  # Be sure to call this somewhere!\n",
    "        \n",
    "    def call(self, inputs, **kwargs):\n",
    "        fea_extract = []\n",
    "        for i, j in itertools.combinations(range(self.num_fields), 2):\n",
    "            fea_embed_i = inputs[:, i:i + 1, :]\n",
    "            # fea_embed_i = Dense(self.embed_size)(fea_embed_i)\n",
    "            fea_embed_i = tf.reshape(fea_embed_i, [-1, self.inter_fields, int(self.embed_size / self.inter_fields)])\n",
    "            \n",
    "            fea_embed_j = inputs[:, j:j + 1, :]\n",
    "            # fea_embed_j = Dense(self.embed_size)(fea_embed_j)\n",
    "            fea_embed_j = tf.reshape(fea_embed_j, [-1, self.inter_fields, int(self.embed_size / self.inter_fields)])\n",
    "            # [:, 2, 8]\n",
    "            weight = Dense(1, activation='sigmoid')(tf.concat([fea_embed_i[:, 0], fea_embed_j[:, 0]], axis=1))\n",
    "            # cross_term = tf.concat([fea_embed_i, fea_embed_j], axis=2)\n",
    "            # cross_term = Dense(self.embed_size)(cross_term)\n",
    "            fm = tf.reduce_sum(fea_embed_i[:, 1] * fea_embed_j[:, 1], axis=1, keep_dims=True)\n",
    "            cross_term = weight * fm\n",
    "        \n",
    "            fea_extract.append(cross_term)\n",
    "        # [:, 2 * 325, 8]\n",
    "        fea_extract = tf.concat(fea_extract, axis=1)\n",
    "        \n",
    "        return fea_extract\n",
    "    \n",
    "#     def compute_output_shape(self, input_shape):\n",
    "#         return (None, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ML(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(ML, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.flatten_size = input_shape[-1]\n",
    "        super(ML, self).build(input_shape)  # Be sure to call this somewhere!\n",
    "        \n",
    "    def call(self, inputs, **kwargs):\n",
    "        dnn1 = Dense(256, activation='relu')(inputs)\n",
    "        dnn1 = Dense(128, activation='relu')(dnn1)\n",
    "        dnn1 = Dense(1)(dnn1)\n",
    "\n",
    "        dnn2 = Dense(256, activation='relu')(inputs)\n",
    "        dnn2 = Dense(128, activation='relu')(dnn2)\n",
    "        dnn2 = Dense(1)(dnn2)\n",
    "\n",
    "        dnn_logit = 0.5 * dnn1 + 0.5 * dnn2\n",
    "        dnn = tf.sigmoid(dnn_logit)\n",
    "        \n",
    "        #kd_loss = 0.01 *(K.binary_crossentropy(dnn, dnn1, from_logits=True) + K.binary_crossentropy(dnn, dnn2, from_logits=True))\n",
    "        #self.add_loss(kd_loss)\n",
    "\n",
    "        return dnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dnn_model(alpha):\n",
    "    input_list = Input(shape=(len(use_features),))\n",
    "    embed_list = []\n",
    "#     fm_list = []\n",
    "#     seq_list = []\n",
    "#     feature_list = []\n",
    "    \n",
    "    for i in range(len(sparse_features)):\n",
    "        input_element = input_list[:, i:i + 1]\n",
    "        embed_layer = Embedding(input_dim=input_embedding_dim_list[i], output_dim=8)(input_element)\n",
    "        embed_list.append(embed_layer)\n",
    "        \n",
    "#     for i in range(len(sparse_features), len(use_features)):\n",
    "#         input_element = input_list[:, i:i + 1]\n",
    "#         embed_list.append(input_element)\n",
    "        \n",
    "    sparse_embed = SENET_V2()(embed_list)\n",
    "        \n",
    "#     for i in range(len(sparse_features)):\n",
    "#         input_element = input_list[:, i:i + 1]\n",
    "#         embed_layer = Embedding(input_dim=input_embedding_dim_list[i], output_dim=16)(input_element)\n",
    "#         fm_list.append(embed_layer)\n",
    "    \n",
    "#     sparse_embed = Concatenate(name='all_embedding', axis=1)(embed_list)\n",
    "    all_embed = Concatenate()([Flatten()(sparse_embed), input_list[:, len(sparse_features):]])\n",
    "#     fm = FM()(sparse_embed)\n",
    "#     fm = Dense(1)(fm)\n",
    "    \n",
    "#     lr = Dense(1)(all_embed)\n",
    "\n",
    "#     cross_net_1 = CrossNet_V2()(all_embed)\n",
    "#     cross_net_1 = Dense(1)(cross_net_1)\n",
    "    \n",
    "#     cross_net_2 = CrossNet_V2()(all_embed)\n",
    "#     cross_net_2 = Dense(1)(cross_net_2)\n",
    "    \n",
    "#     cross_logit = 0.5 * cross_net_1 + 0.5 * cross_net_2\n",
    "    \n",
    "    dnn1 = Dense(256, activation='relu')(all_embed)\n",
    "    dnn1 = Dense(128, activation='relu')(dnn1)\n",
    "    dnn1 = Dense(1)(dnn1)\n",
    "    \n",
    "    dnn2 = Dense(256, activation='relu')(all_embed)\n",
    "    dnn2 = Dense(128, activation='relu')(dnn2)\n",
    "    dnn2 = Dense(1)(dnn2)\n",
    "    \n",
    "    dnn3 = Dense(256, activation='relu')(all_embed)\n",
    "    dnn3 = Dense(128, activation='relu')(dnn3)\n",
    "    dnn3 = Dense(1)(dnn3)\n",
    "    \n",
    "    dnn_logit = (dnn1 + dnn2 + dnn3) / 3\n",
    "    dnn = tf.sigmoid(dnn_logit)\n",
    "#     kd_loss = alpha * (K.binary_crossentropy(dnn, dnn1, from_logits=True) + K.binary_crossentropy(dnn, dnn2, from_logits=True))\n",
    "    \n",
    "#     dnn = Dense(256, activation='relu')(all_embed)\n",
    "#     dnn = Dense(128, activation='relu')(dnn)\n",
    "#     dnn = Dense(1)(dnn)\n",
    "#     fm = Dense(1)(fm)\n",
    "    \n",
    "#     final = Add()([dnn_logit, cross_logit])\n",
    "\n",
    "#     output = Dense(1, activation='sigmoid')(dnn)\n",
    "    \n",
    "    model = Model(inputs=[input_list], outputs=dnn)\n",
    "#     model.add_loss(kd_loss)\n",
    "    return model\n",
    "\n",
    "reset_keras()\n",
    "# model, kd_loss = dnn_model()\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "class lossRecord(Callback):\n",
    "    def __init__(self, log_dir):\n",
    "        super(Callback, self).__init__()  \n",
    "        self.writer = tf.summary.FileWriter(log_dir)\n",
    "        self.num = 0\n",
    "        \n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.loss = []\n",
    "        self.auc = []\n",
    "        self.val_loss = []\n",
    "        self.val_auc = []\n",
    "    \n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        self.num + 1\n",
    "        self.loss = logs.get('loss')\n",
    "        self.auc = logs.get('auroc')\n",
    "        self.val_loss = logs.get('val_loss')\n",
    "        self.val_auc = logs.get('val_auroc')\n",
    "\n",
    "        summary = tf.Summary()\n",
    "        summary.value.add(tag='train_loss', simple_value=self.loss)\n",
    "        summary.value.add(tag='train_auc', simple_value=self.auc)\n",
    "        summary.value.add(tag='val_loss', simple_value=self.val_loss)\n",
    "        summary.value.add(tag='val_auc', simple_value=self.val_auc)     \n",
    "        self.writer.add_summary(summary, self.num)\n",
    "        self.writer.flush()\n",
    "        \n",
    "# class Mylosscallback(Callback):\n",
    "#     def __init__(self, log_dir):\n",
    "#         super(Callback, self).__init__()  \n",
    "#         self.writer = tf.summary.FileWriter(log_dir)\n",
    "#         self.num=0\n",
    "#     def on_train_begin(self, logs={}):\n",
    "#         self.losses = {'batch':[], 'epoch':[]}\n",
    "#         self.accuracy = {'batch':[], 'epoch':[]}\n",
    "#         self.val_loss = {'batch':[], 'epoch':[]}\n",
    "#         self.val_acc = {'batch':[], 'epoch':[]}\n",
    "    \n",
    "#     def on_batch_end(self, batch, logs={}):\n",
    "#         self.num=self.num+1\n",
    "#         self.losses=logs.get('loss')\n",
    "#         self.accuracy=logs.get('acc')\n",
    "#         self.val_loss=logs.get('val_loss')\n",
    "#         self.val_acc=logs.get('val_acc')\n",
    "#         print('debug success!!!')\n",
    "#         summary = tf.Summary()\n",
    "#         summary.value.add(tag='losses', simple_value=self.losses)\n",
    "#         summary.value.add(tag='accuracy', simple_value=self.accuracy)\n",
    "#         summary.value.add(tag='val_loss', simple_value=self.val_loss)\n",
    "#         summary.value.add(tag='val_acc', simple_value=self.val_acc)     \n",
    "#         self.writer.add_summary(summary, self.num)\n",
    "#         self.writer.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2238/2238 [==============================] - 87s 39ms/step - loss: 0.4517 - auroc: 0.7988 - val_loss: 0.4457 - val_auroc: 0.8056\n",
      "gc: 0\n"
     ]
    }
   ],
   "source": [
    "reset_keras()\n",
    "batch_size = 2048 * 8\n",
    "epochs = 1\n",
    "model_count = 1\n",
    "\n",
    "score_list = []\n",
    "\n",
    "# filepath = './model/dnn/dnn_0%s.h5' % (model_count)\n",
    "# checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, mode='min', save_best_only=True, save_weights_only=True)\n",
    "# reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, mode='min', patience=0, verbose=1)\n",
    "# earlystopping = EarlyStopping(monitor='val_loss', patience=2, mode='min', min_delta=0.00002, verbose=1)\n",
    "# for i in range(11):\n",
    "#     log = record_logs('mln_{}'.format(i), 'mln.log')\n",
    "# callbacks = [checkpoint, reduce_lr, earlystopping, log]\n",
    "# losslog = lossRecord(\"./log\")\n",
    "#     callbacks = [log]\n",
    "optimizer = Adam(lr=0.01)\n",
    "model = dnn_model(i / 10)\n",
    "# model = multi_gpu_model(model, 2)\n",
    "# print(gc.collect())\n",
    "# model.add_loss(tf.nn.sigmoid_cross_entropy_with_logits(labels=fold_train_y, logits=dnn))\n",
    "# model.add_loss(kd_loss)\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=[auroc])\n",
    "history = model.fit_generator(gen_data(fold_train_x, fold_train_y, batch_size=batch_size),\n",
    "                              validation_data=gen_data(fold_valid_x, fold_valid_y, batch_size=batch_size),\n",
    "                              epochs=epochs, verbose=1, shuffle=True, callbacks=callbacks)\n",
    "# score_list.append(history)\n",
    "reset_keras()\n",
    "print('gc:', gc.collect())\n",
    "# history = model.fit(fold_train_x, fold_train_y, batch_size=batch_size,\n",
    "#                     validation_data=(fold_valid_x, fold_valid_y),\n",
    "#                     epochs=epochs, verbose=1, shuffle=True, callbacks=callbacks)\n",
    "# pred = model.predict(fold_valid_x, batch_size=batch_size, verbose=1)\n",
    "# auc = roc_auc_score(fold_valid_y, pred)\n",
    "# print(auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((36667392, 39), (9158656, 39))"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fold_train_x.shape, fold_valid_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.24891101431238355"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((0.8055 - 0.8035) / 0.8035)  * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold_train_x = fold_train_x.iloc[:-5101]\n",
    "fold_valid_x = fold_valid_x.iloc[:-9468]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dnn\n",
    "# 2239/2239 [==============================] - 73s 32ms/step - loss: 0.4533 - auroc: 0.7971 - val_loss: 0.4471 - val_auroc: 0.8040\n",
    "\n",
    "# deepfm\n",
    "# 2239/2239 [==============================] - 76s 34ms/step - loss: 0.4527 - auroc: 0.7977 - val_loss: 0.4467 - val_auroc: 0.8044\n",
    "\n",
    "# crossnet\n",
    "# 2239/2239 [==============================] - 101s 45ms/step - loss: 0.4531 - auroc: 0.7974 - val_loss: 0.4470 - val_auroc: 0.8041\n",
    "\n",
    "# crossnet v2\n",
    "# 2239/2239 [==============================] - 270s 120ms/step - loss: 0.4507 - auroc: 0.7999 - val_loss: 0.4446 - val_auroc: 0.8069\n",
    "\n",
    "# crossnet2 v2\n",
    "# 2239/2239 [==============================] - 474s 212ms/step - loss: 0.4503 - auroc: 0.8004 - val_loss: 0.4443 - val_auroc: 0.8072\n",
    "\n",
    "# se-crossnet2 v2\n",
    "# 2239/2239 [==============================] - 483s 216ms/step - loss: 0.4501 - auroc: 0.8005 - val_loss: 0.4441 - val_auroc: 0.8074\n",
    "\n",
    "# se-dnn \n",
    "# 2239/2239 [==============================] - 76s 34ms/step - loss: 0.4522 - auroc: 0.7983 - val_loss: 0.4465 - val_auroc: 0.8051\n",
    "\n",
    "# se-dnn2\n",
    "# 2239/2239 [==============================] - 81s 36ms/step - loss: 0.4518 - auroc: 0.7987 - val_loss: 0.4457 - val_auroc: 0.8055\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 559/2239 [======>.......................] - ETA: 1:01 - loss: 0.4481 - auroc: 0.8033\n",
      "Epoch 00001: val_loss did not improve from 0.44681\n",
      "2239/2239 [==============================] - 492s 220ms/step - loss: 0.4346 - auroc: 0.8177 - val_loss: 0.4481 - val_auroc: 0.8033\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f818c14c610>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(gen_data(fold_train_x, fold_train_y, batch_size=batch_size),\n",
    "                              validation_data=gen_data(fold_valid_x, fold_valid_y, batch_size=batch_size),\n",
    "                              epochs=epochs, verbose=1, shuffle=True, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dnn 16embed 256dnn\n",
    "# 2239/2239 [==============================] - 92s 41ms/step - loss: 0.4537 - auroc: 0.7965 - val_loss: 0.4478 - val_auroc: 0.8035\n",
    "\n",
    "# deepfm 16embed 256dnn\n",
    "# 2239/2239 [==============================] - 97s 44ms/step - loss: 0.4530 - auroc: 0.7972 - val_loss: 0.4471 - val_auroc: 0.8040\n",
    "\n",
    "# gate dnn 16embed 256dnn\n",
    "# 2239/2239 [==============================] - 96s 43ms/step - loss: 0.4529 - auroc: 0.7975 - val_loss: 0.4466 - val_auroc: 0.8046\n",
    "\n",
    "# gate deepfm 16embed 256dnn\n",
    "# 2239/2239 [==============================] - 113s 50ms/step - loss: 0.4521 - auroc: 0.7984 - val_loss: 0.4463 - val_auroc: 0.8049\n",
    "\n",
    "# deepfm 16embed not shared 256 dnn\n",
    "# 2239/2239 [==============================] - 157s 70ms/step - loss: 0.4539 - auroc: 0.7964 - val_loss: 0.4477 - val_auroc: 0.8034\n",
    "\n",
    "# gate deepfm 8embed not shared 256 dnn\n",
    "# 2239/2239 [==============================] - 161s 72ms/step - loss: 0.4520 - auroc: 0.7985 - val_loss: 0.4461 - val_auroc: 0.8051\n",
    "\n",
    "# gate deepfm 16embed not shared 256 dnn\n",
    "# 2239/2239 [==============================] - 189s 84ms/step - loss: 0.4519 - auroc: 0.7986 - val_loss: 0.4460 - val_auroc: 0.8053\n",
    "\n",
    "# multi-head self-attention 16embed dnn\n",
    "# 2239/2239 [==============================] - 126s 56ms/step - loss: 0.4565 - auroc: 0.7935 - val_loss: 0.4499 - val_auroc: 0.8009\n",
    "\n",
    "# multi-head self-attention deepfm not shared 16embed 256 dnn\n",
    "# 2239/2239 [==============================] - 224s 100ms/step - loss: 0.4576 - auroc: 0.7924 - val_loss: 0.4505 - val_auroc: 0.8010\n",
    "\n",
    "# senet' 3layer field_size reduction_size field_size sigmoid dnn 16embed 256\n",
    "# 2239/2239 [==============================] - 95s 42ms/step - loss: 0.4516 - auroc: 0.7989 - val_loss: 0.4458 - val_auroc: 0.8061\n",
    "\n",
    "# senet' 1layer field_size sigmoid deepfm 16embed not shared 256 dnn\n",
    "# 2239/2239 [==============================] - 160s 71ms/step - loss: 0.4517 - auroc: 0.7987 - val_loss: 0.4456 - val_auroc: 0.8057\n",
    "\n",
    "# senet' 3layer field_size reduction_size field_size sigmoid deepfm 16embed not shared 256 dnn\n",
    "# 2239/2239 [==============================] - 167s 74ms/step - loss: 0.4505 - auroc: 0.8002 - val_loss: 0.4444 - val_auroc: 0.8071\n",
    "\n",
    "# ---------------------------------------------------------------------------------------------------------------------------------\n",
    "# senet' dcn \n",
    "# 2239/2239 [==============================] - 207s 92ms/step - loss: 0.4518 - auroc: 0.7988 - val_loss: 0.4454 - val_auroc: 0.8059\n",
    "\n",
    "# senet' crossfm\n",
    "# 2239/2239 [==============================] - 264s 118ms/step - loss: 0.4498 - auroc: 0.8010 - val_loss: 0.4440 - val_auroc: 0.8077\n",
    "# ---------------------------------------------------------------------------------------------------------------------------------\n",
    "# double embedding\n",
    "# 2239/2239 [==============================] - 187s 83ms/step - loss: 0.4534 - auroc: 0.7968 - val_loss: 0.4473 - val_auroc: 0.8038"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(305, 1)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lr 1embed\n",
    "# 2239/2239 [==============================] - 79s 35ms/step - loss: 0.4812 - auroc: 0.7619 - val_loss: 0.4775 - val_auroc: 0.7669\n",
    "\n",
    "# True lr 1embed\n",
    "# 2239/2239 [==============================] - 68s 31ms/step - loss: 0.4822 - auroc: 0.7607 - val_loss: 0.4777 - val_auroc: 0.7667\n",
    "\n",
    "# lr 8embed\n",
    "# 2239/2239 [==============================] - 81s 36ms/step - loss: 0.4811 - auroc: 0.7621 - val_loss: 0.4780 - val_auroc: 0.7664\n",
    "\n",
    "# fm 8embed\n",
    "# 2239/2239 [==============================] - 87s 39ms/step - loss: 0.4797 - auroc: 0.7652 - val_loss: 0.4731 - val_auroc: 0.7734\n",
    "\n",
    "# fm + lr 8embed 1embed\n",
    "# 2239/2239 [==============================] - 133s 59ms/step - loss: 0.4764 - auroc: 0.7683 - val_loss: 0.4702 - val_auroc: 0.7764\n",
    "\n",
    "# deepfm 256dnn 16embed\n",
    "# 2239/2239 [==============================] - 160s 72ms/step - loss: 0.4530 - auroc: 0.7974 - val_loss: 0.4471 - val_auroc: 0.8039\n",
    "\n",
    "# dnn 256dnn 16embed\n",
    "# 2239/2239 [==============================] - 143s 64ms/step - loss: 0.4538 - auroc: 0.7964 - val_loss: 0.4476 - val_auroc: 0.8035\n",
    "\n",
    "# dnn 256 128dnn 16embed\n",
    "# 2239/2239 [==============================] - 154s 69ms/step - loss: 0.4537 - auroc: 0.7966 - val_loss: 0.4474 - val_auroc: 0.8037\n",
    "\n",
    "# dcn_v2 8embed 3layer\n",
    "# 4477/4477 [==============================] - 403s 90ms/step - loss: 0.4505 - auroc: 0.8003 - val_loss: 0.4454 - val_auroc: 0.8063\n",
    "\n",
    "# dcn_v2 8embed 200dnn 3layer\n",
    "# 2239/2239 [==============================] - 364s 162ms/step - loss: 0.4506 - auroc: 0.7999 - val_loss: 0.4449 - val_auroc: 0.8066\n",
    "\n",
    "# dcn_mixed 8emebd 200dnn 32low_rank 4num_experts 2layer_num\n",
    "# 2239/2239 [==============================] - 502s 224ms/step - loss: 0.4515 - auroc: 0.7990 - val_loss: 0.4456 - val_auroc: 0.8056\n",
    "\n",
    "# dcn_mixed 8emebd 200dnn 32low_rank 4num_experts 3layer_num\n",
    "# 2239/2239 [==============================] - 680s 304ms/step - loss: 0.4517 - auroc: 0.7988 - val_loss: 0.4457 - val_auroc: 0.8055\n",
    "\n",
    "# dcn_mixed 8emebd 200dnn 32low_rank 6num_experts 2layer_num\n",
    "# 2239/2239 [==============================] - 675s 301ms/step - loss: 0.4522 - auroc: 0.7982 - val_loss: 0.4465 - val_auroc: 0.8056"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gc.collect:  0\n",
      "Device mapping:\n",
      "/job:localhost/replica:0/task:0/device:XLA_CPU:0 -> device: XLA_CPU device\n",
      "/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: Tesla V100-SXM2-32GB, pci bus id: 0000:00:08.0, compute capability: 7.0\n",
      "/job:localhost/replica:0/task:0/device:GPU:1 -> device: 1, name: Tesla V100-SXM2-32GB, pci bus id: 0000:00:09.0, compute capability: 7.0\n",
      "/job:localhost/replica:0/task:0/device:GPU:2 -> device: 2, name: Tesla V100-SXM2-32GB, pci bus id: 0000:00:0a.0, compute capability: 7.0\n",
      "/job:localhost/replica:0/task:0/device:GPU:3 -> device: 3, name: Tesla V100-SXM2-32GB, pci bus id: 0000:00:0b.0, compute capability: 7.0\n",
      "/job:localhost/replica:0/task:0/device:XLA_GPU:0 -> device: XLA_GPU device\n",
      "/job:localhost/replica:0/task:0/device:XLA_GPU:1 -> device: XLA_GPU device\n",
      "/job:localhost/replica:0/task:0/device:XLA_GPU:2 -> device: XLA_GPU device\n",
      "/job:localhost/replica:0/task:0/device:XLA_GPU:3 -> device: XLA_GPU device\n",
      "\n",
      "Fold:  1\n",
      "####################################################################################################\n",
      "WARNING:tensorflow:From /opt/conda/envs/tensorflow_py3/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 2048 * 4\n",
    "epochs = 20\n",
    "model_count = 2\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5, random_state=seed, shuffle=True)\n",
    "sub = np.zeros((test_df.shape[0], 2))\n",
    "oof_pred = np.zeros((train_df.shape[0], 2))\n",
    "score = []\n",
    "score_list = []\n",
    "count = 1\n",
    "\n",
    "for i, (train_index, valid_index) in enumerate(skf.split(train_df, train_df['label'])):\n",
    "    reset_keras()\n",
    "    print('Fold: ', count)\n",
    "    print(\"##\" * 50)\n",
    "    filepath = './model/dnn/dnn_0%s_0%s.h5' % (model_count, count)\n",
    "    checkpoint = ModelCheckpoint(filepath, monitor='val_auroc', verbose=1, mode='max', save_best_only=True, save_weights_only=True)\n",
    "    reduce_lr = ReduceLROnPlateau(monitor='val_auroc', factor=0.5, mode='max', patience=2, verbose=1)\n",
    "    earlystopping = EarlyStopping(monitor='val_auroc', patience=4, mode='max', restore_best_weights=True, min_delta=0.0001, verbose=1)\n",
    "    callbacks = [checkpoint, reduce_lr, earlystopping]\n",
    "    optimizer = Lookahead(RAdam(learning_rate=0.01), sync_period=20)\n",
    "    model = dnn_model()\n",
    "    if count == 1:\n",
    "        model.summary()\n",
    "    model = multi_gpu_model(model, 4)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=[auroc])\n",
    "\n",
    "    fold_train_x = train_df[use_features].iloc[train_index]\n",
    "    fold_train_y = to_categorical(train_df['label'].iloc[train_index])\n",
    "    fold_valid_x = train_df[use_features].iloc[valid_index]\n",
    "    fold_valid_y = to_categorical(train_df['label'].iloc[valid_index])\n",
    "    \n",
    "    history = model.fit(fold_train_x, fold_train_y, validation_data=(fold_valid_x, fold_valid_y),\n",
    "                        batch_size=batch_size, epochs=epochs, verbose=1, shuffle=True, callbacks=callbacks)\n",
    "    model.load_weights(filepath)\n",
    "    oof_pred[valid_index] = model.predict(fold_valid_x, batch_size=batch_size, verbose=1)\n",
    "    pred = model.predict(test_df[use_features], batch_size=batch_size, verbose=1) / skf.n_splits\n",
    "    sub += pred\n",
    "    score_list.append(history.history)\n",
    "    score.append(np.max(history.history['val_auroc']))\n",
    "    \n",
    "    del fold_train_x\n",
    "    del fold_train_y\n",
    "    del fold_valid_x\n",
    "    del fold_valid_y\n",
    "    print('gc:', gc.collect())\n",
    "    \n",
    "    with open('./prob/dnn/dnn_0%s_0%s_prob.h5' % (model_count, count), 'wb') as f:\n",
    "        pickle.dump(pred, f)\n",
    "\n",
    "    with open('./prob/dnn/dnn_0%s_score.h5' % model_count, 'wb') as f:\n",
    "        pickle.dump(score_list, f)\n",
    "        \n",
    "    with open('./prob/dnn_oof_0%s_prob.h5' % model_count, 'wb') as f:\n",
    "        pickle.dump(oof_pred, f)\n",
    "        \n",
    "    with open('./prob/dnn/dnn_0%s_prob.h5' % model_count, 'wb') as f:\n",
    "        pickle.dump(sub, f)\n",
    "        \n",
    "    reset_keras()\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000000/1000000 [==============================] - 6s 6us/step\n"
     ]
    }
   ],
   "source": [
    "model.load_weights(filepath)\n",
    "pred = model.predict(test_df[use_features], batch_size=batch_size, verbose=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
